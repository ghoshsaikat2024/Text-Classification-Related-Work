{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\saika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\saika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "nltk.download('wordnet') #For using WordNetLemmatizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404351 entries, 0 to 404350\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            404351 non-null  int64 \n",
      " 1   qid1          404351 non-null  int64 \n",
      " 2   qid2          404351 non-null  int64 \n",
      " 3   question1     404350 non-null  object\n",
      " 4   question2     404349 non-null  object\n",
      " 5   is_duplicate  404351 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n",
      "None\n",
      "   id  qid1  qid2                                          question1  \\\n",
      "0   0     1     2  What is the step by step guide to invest in sh...   \n",
      "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
      "2   2     5     6  How can I increase the speed of my internet co...   \n",
      "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
      "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
      "\n",
      "                                           question2  is_duplicate  \n",
      "0  What is the step by step guide to invest in sh...             0  \n",
      "1  What would happen if the Indian government sto...             0  \n",
      "2  How can Internet speed be increased by hacking...             0  \n",
      "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
      "4            Which fish would survive in salt water?             0  \n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r'questions.csv\\questions.csv')\n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id     qid1   qid2   question1  question2  is_duplicate\n",
       "False  False  False  False      False      False           404348\n",
       "                                True       False                2\n",
       "                     True       False      False                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id     qid1   qid2   question1  question2  is_duplicate\n",
       "False  False  False  False      False      False           404348\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing any rows with even a single null value.\n",
    "data=data.dropna(axis=0)  #axis:0 in pandas mean along the row.\n",
    "data.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello what lovely morning'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_preprocessor(text):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    tokens=word_tokenize(text)\n",
    "    tokens=[word.lower() for word in tokens if word.isalpha() and len(word)>=2]\n",
    "    tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "#Checking the function.\n",
    "text_preprocessor(\"Hello what a lovely Morning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now we will apply the previous function in our question columns.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saika\\AppData\\Local\\Temp\\ipykernel_17796\\3738765822.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data[['question1', 'question2']] = data[['question1', 'question2']].applymap(text_preprocessor)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can increase the speed of my internet conn...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am mentally very lonely how can solve it</td>\n",
       "      <td>find the remainder when math is divided by</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4              what is the story of kohinoor diamond   \n",
       "2   2     5     6  how can increase the speed of my internet conn...   \n",
       "3   3     7     8       why am mentally very lonely how can solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  what is the step by step guide to invest in sh...             0  \n",
       "1  what would happen if the indian government sto...             0  \n",
       "2  how can internet speed be increased by hacking...             0  \n",
       "3         find the remainder when math is divided by             0  \n",
       "4             which fish would survive in salt water             0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['question1', 'question2']] = data[['question1', 'question2']].applymap(text_preprocessor)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now we will extract features using TF-IDF.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808696,)\n",
      "Question1 column feature space shape:(404348, 68844)\n",
      "Question2 column feature space shape:(404348, 68844)\n"
     ]
    }
   ],
   "source": [
    "'''Since the vocab length of question1 and question2 column could be different so the to creating same length feature vector for all questions\n",
    "I created a stack of all the question and thereafter created the feature vector.After that sliced the qs1 and qs2 coulmns from this stacked column of features.'''\n",
    "#Here first we are creating the question stack.\n",
    "question_stack=pd.concat([data['question1'],data['question2']])\n",
    "print(question_stack.shape)\n",
    "\n",
    "#Here I am considering an unigram model.\n",
    "tf_vectorizor=TfidfVectorizer(ngram_range=(1,1))\n",
    "qs_vector=tf_vectorizor.fit_transform(question_stack)\n",
    "\n",
    "qs1_vector,qs2_vector=qs_vector[:data['question1'].shape[0]],qs_vector[data['question1'].shape[0]:]\n",
    "\n",
    "print(f'Question1 column feature space shape:{qs1_vector.shape}\\nQuestion2 column feature space shape:{qs2_vector.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now we will be applying cosine similarity to measure the similarity of the questions.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m similarity_score_ls\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(qs1_vector\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m----> 5\u001b[0m     similarity_score\u001b[38;5;241m=\u001b[39m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqs1_vector\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mqs2_vector\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     similarity_score_ls\u001b[38;5;241m.\u001b[39mappend(similarity_score)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(similarity_score_ls)    \n",
      "File \u001b[1;32mG:\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mG:\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1676\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1674\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1676\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32mG:\\Lib\\site-packages\\sklearn\\utils\\extmath.py:208\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    206\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    211\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    215\u001b[0m ):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32mG:\\Lib\\site-packages\\scipy\\sparse\\_base.py:695\u001b[0m, in \u001b[0;36m_spbase.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    694\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Lib\\site-packages\\scipy\\sparse\\_base.py:606\u001b[0m, in \u001b[0;36m_spbase._matmul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot yet multiply a 1d sparse array\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like an array\u001b[39;00m\n\u001b[0;32m    609\u001b[0m other_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(other)\n",
      "File \u001b[1;32mG:\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:514\u001b[0m, in \u001b[0;36m_cs_matrix._matmul_sparse\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    511\u001b[0m K2, N \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    513\u001b[0m major_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap((M, N))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 514\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# convert to this format\u001b[39;00m\n\u001b[0;32m    516\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[0;32m    517\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices))\n\u001b[0;32m    519\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matmat_maxnnz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mG:\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:34\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     32\u001b[0m         arg1 \u001b[38;5;241m=\u001b[39m arg1\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m         arg1 \u001b[38;5;241m=\u001b[39m \u001b[43marg1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     36\u001b[0m         arg1\u001b[38;5;241m.\u001b[39mindptr, arg1\u001b[38;5;241m.\u001b[39mindices, arg1\u001b[38;5;241m.\u001b[39mdata, arg1\u001b[38;5;241m.\u001b[39m_shape\n\u001b[0;32m     37\u001b[0m     )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg1, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[1;32mG:\\Lib\\site-packages\\scipy\\sparse\\_base.py:435\u001b[0m, in \u001b[0;36m_spbase.asformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# Forward the copy kwarg, if it's accepted.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_method()\n",
      "File \u001b[1;32mG:\\Lib\\site-packages\\scipy\\sparse\\_csc.py:52\u001b[0m, in \u001b[0;36m_csc_base.tocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m     49\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n\u001b[0;32m     50\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz, dtype\u001b[38;5;241m=\u001b[39mupcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m---> 52\u001b[0m \u001b[43mcsc_tocsr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m          \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m          \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_csr_container(\n\u001b[0;32m     61\u001b[0m     (data, indices, indptr),\n\u001b[0;32m     62\u001b[0m     shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     64\u001b[0m A\u001b[38;5;241m.\u001b[39mhas_sorted_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Scikit-learn's cosine similarity returns similarity scores for each i th row of X matrix to all row of Y matrix.\n",
    "#That is why I'will iterate through each row and then perform similarity.\n",
    "similarity_score_ls=[]\n",
    "for i in range(qs1_vector.shape[0]):\n",
    "    similarity_score=cosine_similarity(qs1_vector[i],qs2_vector[i])\n",
    "    similarity_score_ls.append(similarity_score)\n",
    "print(similarity_score_ls)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
