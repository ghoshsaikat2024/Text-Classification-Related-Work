{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/saikat/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/saikat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "nltk.download('wordnet') #For using WordNetLemmatizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is: (40000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"text_emotion.csv\")\n",
    "print(\"Dataset shape is:\",data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of sentiments are:\n",
      " sentiment\n",
      "neutral       8638\n",
      "worry         8459\n",
      "happiness     5209\n",
      "sadness       5165\n",
      "love          3842\n",
      "surprise      2187\n",
      "fun           1776\n",
      "relief        1526\n",
      "hate          1323\n",
      "empty          827\n",
      "enthusiasm     759\n",
      "boredom        179\n",
      "anger          110\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_types=data[\"sentiment\"].value_counts()\n",
    "print(\"Types of sentiments are:\\n\",sentiment_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of sentiments are:\n",
      " sentiment\n",
      "0     8638\n",
      "1     8459\n",
      "2     5209\n",
      "3     5165\n",
      "4     3842\n",
      "5     2187\n",
      "6     1776\n",
      "7     1526\n",
      "8     1323\n",
      "9      827\n",
      "10     759\n",
      "11     179\n",
      "12     110\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Changing the categorical variables into numeric form.\n",
    "mapping={\"neutral\":0,\"worry\":1,\"happiness\":2,\"sadness\":3,\"love\":4,\"surprise\":5,\"fun\":6,\"relief\":7,\"hate\":8,\"empty\":9,\"enthusiasm\":10,\"boredom\":11,\"anger\":12}\n",
    "data[\"sentiment\"]=data[\"sentiment\"].map(mapping)\n",
    "\n",
    "#Verifying.\n",
    "sentiment_types=data[\"sentiment\"].value_counts()\n",
    "print(\"Types of sentiments are:\\n\",sentiment_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now we create a function to tokenize the tweets,remove stopwords(i.e frequently used insignificant words).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello not so good morning'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_text(text:str):\n",
    "    '''\n",
    "    This function tokenizes the tweets, removes numeric char based words ,converts all the chars into lowercase and then lemmatizes the words.\n",
    "    The reason we use lemmatization is ,it uses wordnet library to look up origin of a word.Like better/best will be converted to good.\n",
    "    Here we should not use stop words as it will remove words like not/a/very ,since these kind of words which are important for sentiment classification.\n",
    "    Note:Read about Lemmatization and Stemming and their difference .(Stemming just chops last section of the word)\n",
    "    '''\n",
    "    # stop_words=set(stopwords.words('english'))\n",
    "    word_lemmatizer=WordNetLemmatizer()  #It's a class\n",
    "    tokens=word_tokenize(text)\n",
    "    tokens=[word for word in tokens if word.isalpha() ]  #and len(word)>=2\n",
    "    tokens=[word.lower() for word in tokens ]\n",
    "    # tokens=[word for word in tokens if word not in stop_words]\n",
    "    tokens=[word_lemmatizer.lemmatize(word) for word in tokens ]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "#Veryfying the function\n",
    "text=\"Hello! not  so Good Morning.\"\n",
    "process_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>processesed tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>9</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>tiffanylue i know i wa listenin to bad habit e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>3</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>layin n bed with a headache ughhhh waitin on y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>3</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>10</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>want to hang out with friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>0</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>dannycastillo we want to trade with someone wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id  sentiment       author  \\\n",
       "0  1956967341          9   xoshayzers   \n",
       "1  1956967666          3    wannamama   \n",
       "2  1956967696          3    coolfunky   \n",
       "3  1956967789         10  czareaquino   \n",
       "4  1956968416          0    xkilljoyx   \n",
       "\n",
       "                                             content  \\\n",
       "0  @tiffanylue i know  i was listenin to bad habi...   \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...   \n",
       "2                Funeral ceremony...gloomy friday...   \n",
       "3               wants to hang out with friends SOON!   \n",
       "4  @dannycastillo We want to trade with someone w...   \n",
       "\n",
       "                                  processesed tweets  \n",
       "0  tiffanylue i know i wa listenin to bad habit e...  \n",
       "1  layin n bed with a headache ughhhh waitin on y...  \n",
       "2                     funeral ceremony gloomy friday  \n",
       "3                  want to hang out with friend soon  \n",
       "4  dannycastillo we want to trade with someone wh...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying the process_text function on the tweet column\n",
    "data['processesed tweets']=data['content'].apply(process_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words based feature vector shape:(40000, 243282)\n",
      " TF-IDF based feature vector shape:(40000, 243282)\n"
     ]
    }
   ],
   "source": [
    "#Creating feature vector from text using Bag of Words with bigram model .\n",
    "'''In unigram we just take the feature as occurance of a particular word .In ngram we take feature as the occurence of a sequence of n words ,which help us in getting some context.\n",
    "For example I'm not feeling good sentence is taken as a bigram or trigram model manner then we get the  context of negation otherwise individual word occurence like in unigram does not \n",
    "mean anything.\n",
    "Note:To know more read about N-gram model.\n",
    "'''\n",
    "bg_vectorizor=CountVectorizer(ngram_range=(1,2))\n",
    "X_bow=bg_vectorizor.fit_transform(data['processesed tweets'])\n",
    "\n",
    "#Label.\n",
    "Y=data['sentiment']\n",
    "\n",
    "#Creating feature vector from text using Tf-Idf with bigram model.\n",
    "tf_vectorizor=TfidfVectorizer(ngram_range=(1,2))\n",
    "X_tf=tf_vectorizor.fit_transform(data['processesed tweets'])\n",
    "\n",
    "print(f'Bag of Words based feature vector shape:{X_bow.shape}\\n TF-IDF based feature vector shape:{X_tf.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split for vectors created using bag of words\n",
    "X_bow_train,X_bow_test,Y_train,Y_test=train_test_split(X_bow,Y,test_size=0.25,random_state=42)\n",
    "#Train test split for vector/features created using TF_IDF\n",
    "X_tf_train,X_tf_test,Y_train,Y_test=train_test_split(X_tf,Y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Classifying using Logistic Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saikat/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/saikat/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Accuracy: 0.3305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.50      0.44      2183\n",
      "           1       0.35      0.33      0.34      2093\n",
      "           2       0.34      0.34      0.34      1288\n",
      "           3       0.32      0.32      0.32      1314\n",
      "           4       0.43      0.43      0.43       941\n",
      "           5       0.15      0.13      0.14       516\n",
      "           6       0.13      0.11      0.12       421\n",
      "           7       0.20      0.14      0.16       435\n",
      "           8       0.29      0.28      0.29       332\n",
      "           9       0.04      0.03      0.03       203\n",
      "          10       0.01      0.00      0.01       204\n",
      "          11       0.04      0.02      0.03        43\n",
      "          12       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.33     10000\n",
      "   macro avg       0.21      0.20      0.20     10000\n",
      "weighted avg       0.32      0.33      0.32     10000\n",
      "\n",
      "TF-IDF accuracy is: 0.3046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.38      0.39      2183\n",
      "           1       0.39      0.27      0.32      2093\n",
      "           2       0.34      0.30      0.32      1288\n",
      "           3       0.33      0.34      0.33      1314\n",
      "           4       0.45      0.45      0.45       941\n",
      "           5       0.13      0.21      0.16       516\n",
      "           6       0.12      0.19      0.14       421\n",
      "           7       0.16      0.22      0.18       435\n",
      "           8       0.23      0.36      0.28       332\n",
      "           9       0.02      0.02      0.02       203\n",
      "          10       0.04      0.04      0.04       204\n",
      "          11       0.03      0.02      0.03        43\n",
      "          12       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.30     10000\n",
      "   macro avg       0.20      0.21      0.20     10000\n",
      "weighted avg       0.33      0.30      0.31     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting on extracted feature using bag of words.\n",
    "#Note:Here since class imbalance exists so we set class weight to balanced,so that the algo can give more importance to minority class automatically.For more info check scikit-learn docs.\n",
    "clf_bow_log=LogisticRegression(class_weight=\"balanced\",solver=\"sag\",multi_class=\"multinomial\") \n",
    "clf_bow_log.fit(X_bow_train,Y_train)\n",
    "y_pred_bow=clf_bow_log.predict(X_bow_test)\n",
    "print(\"Bag of Words Accuracy:\",accuracy_score(Y_test,y_pred_bow))\n",
    "print(classification_report(Y_test,y_pred_bow))\n",
    "\n",
    "#Fitting on TF-IDF extracted feature.\n",
    "clf_tf_log=LogisticRegression(class_weight=\"balanced\")\n",
    "clf_tf_log.fit(X_tf_train,Y_train)\n",
    "y_pred_tf=clf_tf_log.predict(X_tf_test)\n",
    "print(\"TF-IDF accuracy is:\",accuracy_score(Y_test,y_pred_tf))\n",
    "print(classification_report(Y_test,y_pred_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now Classifying using SVM with rbf kernel.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Accuracy: 0.3316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.45      0.41      2183\n",
      "           1       0.31      0.46      0.37      2093\n",
      "           2       0.32      0.34      0.33      1288\n",
      "           3       0.31      0.29      0.30      1314\n",
      "           4       0.46      0.37      0.41       941\n",
      "           5       0.19      0.14      0.16       516\n",
      "           6       0.14      0.09      0.11       421\n",
      "           7       0.23      0.07      0.10       435\n",
      "           8       0.39      0.19      0.26       332\n",
      "           9       0.05      0.01      0.02       203\n",
      "          10       0.03      0.00      0.01       204\n",
      "          11       0.00      0.00      0.00        43\n",
      "          12       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.33     10000\n",
      "   macro avg       0.22      0.19      0.19     10000\n",
      "weighted avg       0.32      0.33      0.32     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saikat/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/saikat/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/saikat/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF accuracy is: 0.33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.66      0.41      2183\n",
      "           1       0.33      0.38      0.35      2093\n",
      "           2       0.38      0.26      0.31      1288\n",
      "           3       0.35      0.23      0.28      1314\n",
      "           4       0.51      0.34      0.41       941\n",
      "           5       0.27      0.08      0.13       516\n",
      "           6       0.10      0.02      0.03       421\n",
      "           7       0.23      0.02      0.04       435\n",
      "           8       0.45      0.14      0.21       332\n",
      "           9       0.11      0.02      0.03       203\n",
      "          10       0.00      0.00      0.00       204\n",
      "          11       0.00      0.00      0.00        43\n",
      "          12       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.33     10000\n",
      "   macro avg       0.23      0.17      0.17     10000\n",
      "weighted avg       0.32      0.33      0.30     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saikat/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/saikat/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/saikat/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "clf_bow_svm=SVC(class_weight=\"balanced\",random_state=42)\n",
    "clf_bow_svm.fit(X_bow_train,Y_train)\n",
    "y_pred_bow=clf_bow_svm.predict(X_bow_test)\n",
    "print(\"Bag of Words Accuracy:\",accuracy_score(Y_test,y_pred_bow))\n",
    "print(classification_report(Y_test,y_pred_bow))\n",
    "\n",
    "#Fitting on TF-IDF extracted feature.\n",
    "clf_tf_svm=SVC(class_weight=\"balanced\")\n",
    "clf_tf_svm.fit(X_tf_train,Y_train)\n",
    "y_pred_tf=clf_tf_svm.predict(X_tf_test)\n",
    "print(\"TF-IDF accuracy is:\",accuracy_score(Y_test,y_pred_tf))\n",
    "print(classification_report(Y_test,y_pred_tf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
